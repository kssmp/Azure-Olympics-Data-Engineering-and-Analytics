# Azure Olympics Data Engineering and Analytics Project
![Screenshot 2023-09-22 at 9 59 09 PM](https://github.com/kssmp/etl/assets/115448106/8e9f836c-1fcd-4982-97d2-2dfe2b74deb4)
![Screenshot 2023-09-22 at 10 01 41 PM](https://github.com/kssmp/etl/assets/115448106/7838e202-797d-4f45-ae51-6a4c375534cb)
## 1. Introduction

This README provides an overview and setup guide for an Azure-based Olympics data engineering and analytics project. It covers data ingestion, transformation using PySpark, advanced analytics with Azure Synapse, and dashboard creation in Power BI.

## 2. Overview

The project focuses on:

- Fetching raw Olympics data.
- Storing data in Azure Data Lake Storage Gen2.
- Transforming data with PySpark.
- Utilizing Azure Synapse Analytics for advanced analytics.
- Creating interactive Power BI dashboards.

## 3. Prerequisites

Before you start, ensure you have:

- An Azure subscription.
- Azure Data Factory set up.
- Azure Data Lake Storage Gen2 configured.
- Azure Synapse Analytics workspace.
- Power BI Desktop installed.

## 4. Setup

### Azure Resources

1. **Azure Data Factory**: Create and configure data pipelines to fetch and store Olympics data.

2. **Data Lake Storage Gen2**: Set up containers for raw and transformed data.

3. **Azure Synapse Analytics**: Create a workspace for data analytics and integration with Data Lake Storage Gen2.

4. **Power BI Dashboards**: Prepare Power BI workspaces and datasets for your analytics dashboards.

### Data Factory

- Configure data pipelines for data ingestion and storage.


### Data Lake Storage Gen2

- Create containers for raw and transformed data.

### PySpark Transformation

- Develop PySpark scripts for data transformation.
- Store transformed data in Azure Data Lake Storage Gen2.
  


### Synapse Analytics

- Ingest transformed data into Synapse Analytics.
- Perform analytics and store results.

### Power BI Dashboards

- Connect Power BI Desktop to data sources (Synapse or Data Lake Storage Gen2).
- Create interactive dashboards and reports for data visualization.

## 5. Running the Project

1. Verify Azure resource configurations.
2. Trigger Data Factory pipelines for data ingestion.
3. Execute PySpark transformations.
4. Ingest transformed data into Synapse Analytics.
5. Perform analytics and save results.
6. Create Power BI dashboards for visualization.
7. Share dashboards with stakeholders.
